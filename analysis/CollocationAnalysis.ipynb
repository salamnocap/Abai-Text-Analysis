{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset/en.json', 'r') as file:\n",
    "    en = json.load(file)\n",
    "with open('../dataset/ru.json', 'r') as file:\n",
    "    ru = json.load(file)\n",
    "with open('../dataset/kaz.json', 'r') as file:\n",
    "    kz = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_en = set(stopwords.words('english'))\n",
    "stop_words_ru = set(stopwords.words('russian'))\n",
    "stop_words_kz = set(stopwords.words('kazakh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chapters(dictionary):\n",
    "    chapters = []\n",
    "    for part, _ in dictionary.items():\n",
    "        for chapter in dictionary[part]:\n",
    "            chapters.append(chapter)\n",
    "    return chapters\n",
    "kz_chapters_part1, kz_chapters_part2 = get_chapters(kz)[2:9], get_chapters(kz)[10:]\n",
    "en_chapters_part1, en_chapters_part2 = get_chapters(en)[:7], get_chapters(en)[7:]\n",
    "ru_chapters_part1, ru_chapters_part2 = get_chapters(ru)[:7], get_chapters(ru)[7:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_collocations(book_data, part, top_n, language):\n",
    "    # Flatten lists of lists\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "    # Combine tokens for each part and lowercase them\n",
    "    part_tokens = flatten([flatten(chapter) for chapter in book_data[part].values()])\n",
    "    part_tokens_lower = [word.lower() for word in part_tokens]\n",
    "\n",
    "    # Remove stop words\n",
    "    if language == 'english':\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "    elif language == 'russian':\n",
    "        stop_words = set(stopwords.words('russian'))\n",
    "    elif language == 'kazakh':\n",
    "        stop_words = set(stopwords.words('kazakh'))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid language. Supported languages are 'english', 'russian', and 'kazakh'.\")\n",
    "\n",
    "    # Tokenize and remove stop words\n",
    "    part_words = [word for word in part_tokens_lower if word not in stop_words]\n",
    "\n",
    "    # Calculate bigram collocations using PMI\n",
    "    finder = BigramCollocationFinder.from_words(part_words, window_size=5)\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "\n",
    "    # Get top collocations for each part\n",
    "    collocations = finder.nbest(bigram_measures.chi_sq, top_n)\n",
    "    return collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_part1 = calculate_collocations(en, \"part1\", 10, 'english')\n",
    "en_part2 = calculate_collocations(en, \"part2\", 10, 'english')\n",
    "kz_part1 = calculate_collocations(kz, \"part1\", 10, 'kazakh')\n",
    "kz_part2 = calculate_collocations(kz, \"part2\", 10, 'kazakh')\n",
    "ru_part1 = calculate_collocations(ru, \"part1\", 10, 'russian')\n",
    "ru_part2 = calculate_collocations(ru, \"part2\", 10, 'russian')\n",
    "# Create DataFrames for each part and language\n",
    "df_en_part1 = pd.DataFrame(en_part1, columns=['word1_en', 'word2_en'])\n",
    "df_en_part2 = pd.DataFrame(en_part2, columns=['word1_en', 'word2_en'])\n",
    "df_kz_part1 = pd.DataFrame(kz_part1, columns=['word1_kz', 'word2_kz'])\n",
    "df_kz_part2 = pd.DataFrame(kz_part2, columns=['word1_kz', 'word2_kz'])\n",
    "df_ru_part1 = pd.DataFrame(ru_part1, columns=['word1_ru', 'word2_ru'])\n",
    "df_ru_part2 = pd.DataFrame(ru_part2, columns=['word1_ru', 'word2_ru'])\n",
    "\n",
    "book_1 = pd.concat([df_en_part1, df_kz_part1, df_ru_part1], axis=1)\n",
    "book_2 = pd.concat([df_en_part2, df_kz_part2, df_ru_part2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1_en</th>\n",
       "      <th>word2_en</th>\n",
       "      <th>word1_kz</th>\n",
       "      <th>word2_kz</th>\n",
       "      <th>word1_ru</th>\n",
       "      <th>word2_ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aga</td>\n",
       "      <td>sped</td>\n",
       "      <td>төбеңнен</td>\n",
       "      <td>ұрсын</td>\n",
       "      <td>ата</td>\n",
       "      <td>лепетала</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kiss</td>\n",
       "      <td>himshe</td>\n",
       "      <td>қорқа</td>\n",
       "      <td>бұға</td>\n",
       "      <td>главой</td>\n",
       "      <td>дуана</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wider</td>\n",
       "      <td>stalked</td>\n",
       "      <td>азды</td>\n",
       "      <td>қуайық</td>\n",
       "      <td>аулаул</td>\n",
       "      <td>курке</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ata</td>\n",
       "      <td>angen</td>\n",
       "      <td>алуда</td>\n",
       "      <td>оңайдан</td>\n",
       "      <td>больном</td>\n",
       "      <td>простуда</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ata</td>\n",
       "      <td>sped</td>\n",
       "      <td>бақа</td>\n",
       "      <td>жібердім</td>\n",
       "      <td>входите</td>\n",
       "      <td>стоявшего</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>enongn</td>\n",
       "      <td>arasha</td>\n",
       "      <td>бақа</td>\n",
       "      <td>көйлегіңе</td>\n",
       "      <td>выскочили</td>\n",
       "      <td>налетай</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scorpion</td>\n",
       "      <td>lustily</td>\n",
       "      <td>бұға</td>\n",
       "      <td>етекбасты</td>\n",
       "      <td>действовала</td>\n",
       "      <td>айт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apa</td>\n",
       "      <td>azheh</td>\n",
       "      <td>бәрәқалла</td>\n",
       "      <td>архамәррахимин</td>\n",
       "      <td>дразнить</td>\n",
       "      <td>трус</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aa</td>\n",
       "      <td>rights</td>\n",
       "      <td>бәрәқалла</td>\n",
       "      <td>бирахматиқа</td>\n",
       "      <td>желкуйин</td>\n",
       "      <td>кличка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aad</td>\n",
       "      <td>thewe</td>\n",
       "      <td>елім</td>\n",
       "      <td>елімауелім</td>\n",
       "      <td>задумчивый</td>\n",
       "      <td>побежден</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1_en word2_en   word1_kz        word2_kz     word1_ru   word2_ru\n",
       "0       aga     sped   төбеңнен           ұрсын          ата   лепетала\n",
       "1      kiss   himshe      қорқа            бұға       главой      дуана\n",
       "2     wider  stalked       азды          қуайық       аулаул      курке\n",
       "3       ata    angen      алуда         оңайдан      больном   простуда\n",
       "4       ata     sped       бақа        жібердім      входите  стоявшего\n",
       "5    enongn   arasha       бақа       көйлегіңе    выскочили    налетай\n",
       "6  scorpion  lustily       бұға       етекбасты  действовала        айт\n",
       "7       apa    azheh  бәрәқалла  архамәррахимин     дразнить       трус\n",
       "8        aa   rights  бәрәқалла     бирахматиқа     желкуйин     кличка\n",
       "9       aad    thewe       елім      елімауелім   задумчивый   побежден"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_1.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1_en</th>\n",
       "      <th>word2_en</th>\n",
       "      <th>word1_kz</th>\n",
       "      <th>word2_kz</th>\n",
       "      <th>word1_ru</th>\n",
       "      <th>word2_ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chicks</td>\n",
       "      <td>ata</td>\n",
       "      <td>түф</td>\n",
       "      <td>түкрген</td>\n",
       "      <td>стебли</td>\n",
       "      <td>шелестят</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inshalla</td>\n",
       "      <td>amen</td>\n",
       "      <td>апарам</td>\n",
       "      <td>уәдем</td>\n",
       "      <td>лезь</td>\n",
       "      <td>брюхо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accuse</td>\n",
       "      <td>grandfather</td>\n",
       "      <td>бердк</td>\n",
       "      <td>әдлңд</td>\n",
       "      <td>агатай</td>\n",
       "      <td>спрыгивает</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accuse</td>\n",
       "      <td>personally</td>\n",
       "      <td>болыппыз</td>\n",
       "      <td>ашуыңды</td>\n",
       "      <td>благословенна</td>\n",
       "      <td>иншалла</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>becomes</td>\n",
       "      <td>hotter</td>\n",
       "      <td>брбрақ</td>\n",
       "      <td>тұрғыға</td>\n",
       "      <td>богачи</td>\n",
       "      <td>властвовать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>creation</td>\n",
       "      <td>woe</td>\n",
       "      <td>брңнен</td>\n",
       "      <td>малдарың</td>\n",
       "      <td>боль</td>\n",
       "      <td>агатай</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>limb</td>\n",
       "      <td>darkemhbai</td>\n",
       "      <td>бүрктшнң</td>\n",
       "      <td>көшке</td>\n",
       "      <td>дои</td>\n",
       "      <td>сбивай</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lord</td>\n",
       "      <td>woe</td>\n",
       "      <td>бөрктер</td>\n",
       "      <td>шалбарын</td>\n",
       "      <td>заходи</td>\n",
       "      <td>приятель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mason</td>\n",
       "      <td>accomplished</td>\n",
       "      <td>жүрш</td>\n",
       "      <td>аба</td>\n",
       "      <td>защищаю</td>\n",
       "      <td>целился</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>seize</td>\n",
       "      <td>limb</td>\n",
       "      <td>мүдде</td>\n",
       "      <td>брмз</td>\n",
       "      <td>испуг</td>\n",
       "      <td>агатай</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1_en      word2_en  word1_kz  word2_kz       word1_ru     word2_ru\n",
       "0    chicks           ata       түф   түкрген         стебли     шелестят\n",
       "1  inshalla          amen    апарам     уәдем           лезь        брюхо\n",
       "2    accuse   grandfather     бердк     әдлңд         агатай   спрыгивает\n",
       "3    accuse    personally  болыппыз   ашуыңды  благословенна      иншалла\n",
       "4   becomes        hotter    брбрақ   тұрғыға         богачи  властвовать\n",
       "5  creation           woe    брңнен  малдарың           боль       агатай\n",
       "6      limb    darkemhbai  бүрктшнң     көшке            дои       сбивай\n",
       "7      lord           woe   бөрктер  шалбарын         заходи     приятель\n",
       "8     mason  accomplished      жүрш       аба        защищаю      целился\n",
       "9     seize          limb     мүдде      брмз          испуг       агатай"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_2.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_collocations_by_chapter(book_data, part, top_n, language):\n",
    "    # Flatten lists of lists\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "    # Initialize dictionary to store collocations by chapter\n",
    "    collocations_by_chapter = {}\n",
    "\n",
    "    # Combine tokens for each part and lowercase them\n",
    "    for chapter_num, chapter_data in book_data[part].items():\n",
    "        chapter_tokens = flatten(chapter_data)\n",
    "        chapter_tokens_lower = [word.lower() for word in chapter_tokens]\n",
    "\n",
    "        # Remove stop words\n",
    "        if language == 'english':\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "        elif language == 'russian':\n",
    "            stop_words = set(stopwords.words('russian'))\n",
    "        elif language == 'kazakh':\n",
    "            stop_words = set(stopwords.words('kazakh'))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid language. Supported languages are 'english', 'russian', and 'kazakh'.\")\n",
    "\n",
    "        # Tokenize and remove stop words\n",
    "        chapter_words = [word for word in chapter_tokens_lower if word not in stop_words]\n",
    "\n",
    "        # Calculate bigram collocations using PMI\n",
    "        finder = BigramCollocationFinder.from_words(chapter_words, window_size=5)\n",
    "        bigram_measures = BigramAssocMeasures()\n",
    "\n",
    "        # Get top collocations for the chapter\n",
    "        collocations = finder.nbest(bigram_measures.chi_sq, top_n)\n",
    "\n",
    "        # Store collocations in the dictionary\n",
    "        collocations_by_chapter[chapter_num] = collocations\n",
    "\n",
    "    return collocations_by_chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_part1 = calculate_collocations_by_chapter(en, \"part1\", 10, 'english')\n",
    "en_part2 = calculate_collocations_by_chapter(en, \"part2\", 10, 'english')\n",
    "kz_part1 = calculate_collocations_by_chapter(kz, \"part1\", 10, 'kazakh')\n",
    "kz_part2 = calculate_collocations_by_chapter(kz, \"part2\", 10, 'kazakh')\n",
    "ru_part1 = calculate_collocations_by_chapter(ru, \"part1\", 10, 'russian')\n",
    "ru_part2 = calculate_collocations_by_chapter(ru, \"part2\", 10, 'russian')\n",
    "# # Create DataFrames for each part and language\n",
    "# df_en_part1 = pd.DataFrame(en_part1, columns=['word1_en', 'word2_en'])\n",
    "# df_en_part2 = pd.DataFrame(en_part2, columns=['word1_en', 'word2_en'])\n",
    "# df_kz_part1 = pd.DataFrame(kz_part1, columns=['word1_kz', 'word2_kz'])\n",
    "# df_kz_part2 = pd.DataFrame(kz_part2, columns=['word1_kz', 'word2_kz'])\n",
    "# df_ru_part1 = pd.DataFrame(ru_part1, columns=['word1_ru', 'word2_ru'])\n",
    "# df_ru_part2 = pd.DataFrame(ru_part2, columns=['word1_ru', 'word2_ru'])\n",
    "\n",
    "# book_1 = pd.concat([df_en_part1, df_kz_part1, df_ru_part1], axis=1)\n",
    "# book_2 = pd.concat([df_en_part2, df_kz_part2, df_ru_part2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'перед_бродом': [('иншалла', 'аминь'),\n",
       "  ('лезь', 'брюхо'),\n",
       "  ('стебли', 'шелестят'),\n",
       "  ('задрожал', 'выстрелил'),\n",
       "  ('аминь', 'подхватили'),\n",
       "  ('аминь', 'старейшины'),\n",
       "  ('ата', 'приедет'),\n",
       "  ('бедная', 'виновата'),\n",
       "  ('благословенна', 'иншалла'),\n",
       "  ('божью', 'тропу')],\n",
       " 'на_жайляу': [('агатай', 'спрыгивает'),\n",
       "  ('аминь', 'бабушка'),\n",
       "  ('аминь', 'благоговейно'),\n",
       "  ('богачи', 'властвовать'),\n",
       "  ('боевой', 'иду'),\n",
       "  ('бок', 'начинают'),\n",
       "  ('бок', 'расходиться'),\n",
       "  ('боль', 'агатай'),\n",
       "  ('весны', 'бок'),\n",
       "  ('властвовать', 'незабываемым')],\n",
       " 'взгорьями': [('овцы', 'башка'),\n",
       "  ('башка', 'рабы'),\n",
       "  ('будьте', 'счастливы'),\n",
       "  ('всеобщей', 'истории'),\n",
       "  ('жадной', 'жди'),\n",
       "  ('жалости', 'жди'),\n",
       "  ('жди', 'губит'),\n",
       "  ('жди', 'жесток'),\n",
       "  ('жди', 'приход'),\n",
       "  ('идеальный', 'справедлив')],\n",
       " 'по_рытвинам': [('аксарбас', 'шумной'),\n",
       "  ('болтай', 'бесы'),\n",
       "  ('болтай', 'подсказывают'),\n",
       "  ('везде', 'живут'),\n",
       "  ('везде', 'казахи'),\n",
       "  ('волна', 'безысходности'),\n",
       "  ('волна', 'непреодолимой'),\n",
       "  ('горящей', 'успокойся'),\n",
       "  ('громадной', 'везде'),\n",
       "  ('ели', 'тянулся')],\n",
       " 'на_перевале': [('воплем', 'иргизбай'),\n",
       "  ('выбран', 'шубарага'),\n",
       "  ('выгнал', 'семи'),\n",
       "  ('заходи', 'ждет'),\n",
       "  ('заходи', 'приятель'),\n",
       "  ('мамая', 'думы'),\n",
       "  ('одинаковы', 'думы'),\n",
       "  ('повезу', 'обещаю'),\n",
       "  ('распахнула', 'заходи'),\n",
       "  ('семи', 'шкур')],\n",
       " 'на_распутье': [('отчасти', 'самостоятельно'),\n",
       "  ('пойте', 'веселитесь'),\n",
       "  ('съехались', 'пойте'),\n",
       "  ('виновны', 'вашей'),\n",
       "  ('иргизбаю', 'назову'),\n",
       "  ('наказать', 'несет'),\n",
       "  ('приносимого', 'наказать'),\n",
       "  ('продать', 'виновны'),\n",
       "  ('семи', 'козлят'),\n",
       "  ('абаевы', 'выдумки')],\n",
       " 'эпилог': [('хватит', 'воли'),\n",
       "  ('лишь', 'остался'),\n",
       "  ('безлюдная', 'равнина'),\n",
       "  ('великий', 'молюсь'),\n",
       "  ('видом', 'вон'),\n",
       "  ('воли', 'вершине'),\n",
       "  ('воли', 'одиночестве'),\n",
       "  ('воли', 'стойкой'),\n",
       "  ('вон', 'сидят'),\n",
       "  ('вон', 'хохот')]}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_part2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
